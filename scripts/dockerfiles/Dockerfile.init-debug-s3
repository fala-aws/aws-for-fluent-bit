FROM amazon/aws-for-fluent-bit:init-debug-base
COPY ./scripts/dockerfiles/Dockerfile.init-debug-base /Dockerfile.2.init-debug-base

ENV S3_BUCKET ""
ENV S3_KEY_PREFIX issue

RUN yum install -y unzip zip curl gdb

WORKDIR /var/tmp
RUN curl "https://awscli.amazonaws.com/awscli-exe-linux-$(arch).zip" -o "awscliv2.zip"
RUN unzip awscliv2.zip
RUN ./aws/install
RUN rm awscliv2.zip

RUN yum remove unzip -y \
    && yum clean all \
    && rm -rf /var/cache/yum

# Run Fluent Bit from the cores-out folder and collect crash symbols
# Move symbols to /cores folder after processing
RUN mkdir /cores-out
WORKDIR /cores-out

# Upload coredumps to s3 on shutdown
# customer must set BUCKET env var

# Only last CMD command will be executed, automatically replaces the original entrypoint
CMD echo "AWS for Fluent Bit - Debug Init Image with S3 Core Uploader"; \
    if [ "$S3_BUCKET" == "" ]; then \
        echo "Note: Please set S3_BUCKET environment variable to your crash symbol upload destination S3 bucket"; \
    fi; \
    if [ "$S3_KEY_PREFIX" == "issue" ]; then \
        echo "Note: Please set S3_KEY_PREFIX environment variable to a useful identifier - e.g. company name, team name, customer name"; \
    fi; \
    /init/fluent_bit_init_process; \
    chmod +x /init/invoke_fluent_bit.sh; \
    export RANDOM_ID_VALUE=$(($RANDOM%99999))$(($RANDOM%99999))$(($RANDOM%99999)); \
    echo "RANDOM_ID is set to $RANDOM_ID_VALUE"; \
    env RANDOM_ID=$RANDOM_ID_VALUE /init/invoke_fluent_bit.sh; \
    ls /cores-out/core*; \
    export CORE_FILENAME=`basename $S3_KEY_PREFIX`_`date +"%FT%H%M%S"`${HOSTNAME+_host-$HOSTNAME}_${RANDOM_ID_VALUE}; \
    mv `ls /cores-out/core*` ${CORE_FILENAME}.core; \
    cp /fluent-bit/bin/fluent-bit ./${CORE_FILENAME}.executable; \
    gdb -batch -ex 'thread apply all bt full' -ex 'quit' '/fluent-bit/bin/fluent-bit' ${CORE_FILENAME}.core > /cores-out/${CORE_FILENAME}.stacktrace \
    zip -r /${CORE_FILENAME}.all.zip /cores-out; \
    mv /${CORE_FILENAME}.all.zip /cores-out/${CORE_FILENAME}.all.zip; \
    zip /cores-out/${CORE_FILENAME}.core.zip /cores-out/${CORE_FILENAME}.core; \
    rm /cores-out/${CORE_FILENAME}.core; \
    cp /cores-out/* /cores/; \
    aws s3 cp /cores-out s3://${S3_BUCKET}/${S3_KEY_PREFIX}/ --recursive; \
    echo "Stacktrace - ${CORE_FILENAME}.stacktrace:"; \
    cat /cores/${CORE_FILENAME}.stacktrace
